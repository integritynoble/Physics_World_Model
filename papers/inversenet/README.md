# InverseNet: A Benchmark for Inverse-Problem-Aware Calibration and Reconstruction

## Manuscript Skeleton

### Title

InverseNet: Benchmarking Operator Mismatch Calibration Across Compressive Imaging Modalities

### Authors

Physics World Model Team

### Abstract

We introduce InverseNet, a standardised benchmark dataset and evaluation
framework for assessing calibration and reconstruction methods under
operator mismatch in computational imaging.  InverseNet spans three
compressive-imaging modalities (Single-Pixel Camera, CACTI, CASSI) with
systematically varied mismatch types and severities, enabling fair
comparison across four tasks: parameter estimation, mismatch
identification, calibration, and reconstruction.

### 1. Introduction

- Operator mismatch as a key bottleneck in computational imaging
- Gap in standardised benchmarks
- Contributions: dataset, four-task framework, baseline results

### 2. Related Work

- Calibration methods in computational imaging
- Existing benchmarks (fastMRI, KAIST HSI, simulated-only datasets)
- Mismatch-aware reconstruction (plug-and-play, unrolled methods)

### 3. InverseNet Dataset

#### 3.1 Modalities and Operators

- SPC: random +/- 1 measurement matrix
- CACTI: temporal coded-aperture masks with vertical shift
- CASSI: coded aperture with polynomial dispersion model

#### 3.2 Mismatch Families

| Modality | Family           | Parameter(s)          | Severity levels          |
|----------|------------------|-----------------------|--------------------------|
| SPC      | gain             | gain_factor, bias     | mild/moderate/severe     |
| SPC      | mask_error       | flip_fraction         | mild/moderate/severe     |
| CACTI    | mask_shift       | shift_px              | mild/moderate/severe     |
| CACTI    | temporal_jitter  | timing_offset         | mild/moderate/severe     |
| CASSI    | disp_step        | disp_step_delta       | mild/moderate/severe     |
| CASSI    | mask_shift       | mask_dx, mask_dy      | mild/moderate/severe     |
| CASSI    | PSF_blur         | psf_sigma             | mild/moderate/severe     |

#### 3.3 Noise Model

- Poisson shot noise + Gaussian read noise
- Photon levels: 1e3 (low), 1e4 (medium), 1e5 (high)

#### 3.4 Calibration Captures

- Known-pattern measurements for supervised calibration

### 4. Benchmark Tasks

- T1: Operator parameter estimation (theta-error RMSE)
- T2: Mismatch identification (accuracy, F1)
- T3: Calibration (theta-error reduction, CI coverage)
- T4: Reconstruction under mismatch (PSNR, SSIM, SAM)

### 5. Baselines

- Oracle operator (upper bound)
- Wrong operator (lower bound)
- Grid search calibration
- Heuristic mismatch identification
- GAP-TV reconstruction

### 6. Experimental Results

- Tables and figures (TBD -- generated by `run_baselines.py`)
- Error bars from `error_bars.json`
- Leaderboard from `leaderboard.py`

### 7. Discussion

- Impact of severity on calibration difficulty
- Photon-level dependence
- Cross-modality generalisation
- Limitations and future directions

### 8. Conclusion

### References

### Supplementary Material

- Full sweep tables
- Per-sample results
- Dataset generation code

## File structure

```
papers/inversenet/
    README.md                    -- this file (manuscript skeleton)
    README_CASSI.md              -- CASSI validation guide & quick start
    cassi_plan_inversenet.md     -- Detailed CASSI validation plan (1000+ lines)
    scripts/
        validate_cassi_inversenet.py    -- Main CASSI validation script
        generate_cassi_figures.py       -- CASSI visualization generation
        run_all.sh                      -- Complete validation pipeline
    results/
        cassi_validation_results.json   -- Per-scene detailed results
        cassi_summary.json              -- Aggregated statistics
    figures/                            -- Generated figures
        cassi/
            scenario_comparison.png
            method_comparison_heatmap.png
            gap_comparison.png
            psnr_distribution.png
    tables/                             -- Generated tables
        cassi_results_table.csv
```

## CASSI Validation (3. InverseNet Dataset - CASSI Section)

Comprehensive CASSI validation comparing 4 reconstruction methods under operator mismatch.

**See `README_CASSI.md` for detailed documentation.**

### Quick Start

```bash
# Run complete validation pipeline
cd papers/inversenet
bash scripts/run_all.sh --device cuda:0

# Or run individually:
python scripts/validate_cassi_inversenet.py --device cuda:0  # ~2 hours
python scripts/generate_cassi_figures.py                     # ~30 sec
```

### CASSI Benchmark Summary

- **Methods:** GAP-TV, HDNet, MST-S, MST-L
- **Scenarios:** I (Ideal), II (Baseline), IV (Oracle)
- **Scenes:** 10 KAIST hyperspectral (256×256×28)
- **Total Reconstructions:** 120
- **Mismatch:** dx=0.5 px, dy=0.3 px, θ=0.1° (moderate)

**Expected PSNR Hierarchy:**
```
Scenario I (Ideal)    > Scenario IV (Oracle) > Scenario II (Baseline)
    ~36 dB (MST-L)          ~33.6 dB                ~32.3 dB
Gap I→II: ~3.7 dB (mismatch impact)
Gap II→IV: ~1.3 dB (recovery with oracle)
```

## Reproducing results

```bash
# CASSI Validation (NEW - recommended starting point)
cd papers/inversenet
bash scripts/run_all.sh

# Legacy: Generate full InverseNet datasets (SPC, CACTI, CASSI)
python -m experiments.inversenet.gen_spc   --out_dir datasets/inversenet_spc
python -m experiments.inversenet.gen_cacti --out_dir datasets/inversenet_cacti
python -m experiments.inversenet.gen_cassi --out_dir datasets/inversenet_cassi

# Run full baselines
python -m experiments.inversenet.run_baselines

# Generate leaderboard
python -m experiments.inversenet.leaderboard

# Package for distribution
python -m experiments.inversenet.package --verify
```
